{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINE TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 21:55:49.363896: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-04 21:55:49.470652: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-04 21:55:50.978601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from transformers import RobertaTokenizerFast, RobertaForQuestionAnswering, Trainer, TrainingArguments\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"themariolinml/roberta-base-sqaud2-on-medical_meadow_medqa-v1\"\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_name)\n",
    "model = RobertaForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context(row):\n",
    "    \"\"\"\n",
    "    Generates context by using a question-answering pipeline to get answers based on the provided question and context.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from a pandas DataFrame containing 'user_query' and 'answer' fields. \n",
    "                        'user_query' is the question to be answered and 'answer' is the context used for answering.\n",
    "\n",
    "    Returns:\n",
    "        str: The answer generated by the question-answering pipeline. If an error occurs or the answer cannot be retrieved,\n",
    "            an empty string is returned.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If there is an issue with the question-answering pipeline, an exception is caught and an error message\n",
    "                    is printed. The function will return an empty string in such cases.\n",
    "\n",
    "    Notes:\n",
    "        - The function expects the 'pipe' object to be a `transformers.pipeline` configured for question-answering tasks.\n",
    "        - The function verifies if the result from the pipeline contains the key 'answer'. If not, it prints an unexpected \n",
    "        result message and returns an empty string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use the pipeline to get the answer\n",
    "        result = pipe(question=row['user_query'], context=row['answer'])\n",
    "        \n",
    "        # Check if the result contains the 'answer' key\n",
    "        if isinstance(result, dict) and 'answer' in result:\n",
    "            return result['answer']\n",
    "        else:\n",
    "            print(f\"Unexpected result from the pipeline: {result}\")\n",
    "            return ''\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating context for question: {row['user_query']}. Error: {e}\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/csv/train_dataset/df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['user_query', 'answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['context'] = df.apply(generate_context, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/csv/train_dataset/df_generative.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/csv/train_dataset/df_generative.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_query</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lyme disease 12 years ago I was bitten by tick...</td>\n",
       "      <td>Lyme disease tests are used to determine if a ...</td>\n",
       "      <td>Lyme disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raynauds syndrome My sons middle toe turned wh...</td>\n",
       "      <td>Only one finger or toe or parts of one or more...</td>\n",
       "      <td>finger or toe or parts of one or more may be a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>burn to my wrist Hello I burnt my wrist 2 days...</td>\n",
       "      <td>Before giving first aid, it is important to de...</td>\n",
       "      <td>major burn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>treatment of parkinson I AM HAVING PARKINSON F...</td>\n",
       "      <td>you should know that people who have Parkinson...</td>\n",
       "      <td>Parkinson's disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>periventricular heterotopia.  scoliosis  - pos...</td>\n",
       "      <td>Isolated lissencephaly sequence (ILS) is a con...</td>\n",
       "      <td>Isolated lissencephaly sequence (ILS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_query  \\\n",
       "0  lyme disease 12 years ago I was bitten by tick...   \n",
       "1  raynauds syndrome My sons middle toe turned wh...   \n",
       "2  burn to my wrist Hello I burnt my wrist 2 days...   \n",
       "3  treatment of parkinson I AM HAVING PARKINSON F...   \n",
       "4  periventricular heterotopia.  scoliosis  - pos...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Lyme disease tests are used to determine if a ...   \n",
       "1  Only one finger or toe or parts of one or more...   \n",
       "2  Before giving first aid, it is important to de...   \n",
       "3  you should know that people who have Parkinson...   \n",
       "4  Isolated lissencephaly sequence (ILS) is a con...   \n",
       "\n",
       "                                             context  \n",
       "0                                       Lyme disease  \n",
       "1  finger or toe or parts of one or more may be a...  \n",
       "2                                         major burn  \n",
       "3                                Parkinson's disease  \n",
       "4              Isolated lissencephaly sequence (ILS)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_query    0\n",
       "answer        0\n",
       "context       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['context'] = df['context'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['user_query', 'answer', 'context'],\n",
       "        num_rows: 356\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['user_query', 'answer', 'context'],\n",
       "        num_rows: 90\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['user_query'],\n",
    "        examples['context'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_offsets_mapping=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e924826a64f44490830467c1365cec88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8672d278ccc04b1c895dc477872ff9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = train_test_split.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_answers(examples):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, (answer, context) in enumerate(zip(examples['answer'], examples['context'])):\n",
    "        start_idx = context.find(answer)\n",
    "        if start_idx == -1:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            start_positions.append(tokenizer.encode(context[:start_idx], truncation=True, return_tensors='pt').size(1))\n",
    "            end_positions.append(start_positions[-1] + len(tokenizer.encode(answer, truncation=True, return_tensors='pt')) - 1)\n",
    "\n",
    "    examples['start_positions'] = start_positions\n",
    "    examples['end_positions'] = end_positions\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec9139013db49a9889e54fd7ad7f4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a3494d8cab42b3a9c10cfa7cef6075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.map(preprocess_answers, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natalia/DATA_ANALYTICS/QUALENTUM/Sprint_5 TFB/TFB_Natalia_Barquin/.venv/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Configurar los argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f557dd30b9254650b366e6b3ab5d631c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = trainer.evaluate()\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./my_model\")\n",
    "tokenizer.save_pretrained(\"./my_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
